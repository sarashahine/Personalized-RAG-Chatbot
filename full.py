from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
import os
from io import BytesIO
from dotenv import load_dotenv
from elevenlabs.client import ElevenLabs
import openai
from sentence_transformers import SentenceTransformer
import faiss
import json
import sqlite3
import threading
from typing import Dict, List
import arabic_reshaper
from bidi.algorithm import get_display

# ------------------ Load APIs ------------------
load_dotenv()

class ChatHistoryManager:
    def __init__(self, db_path: str = "chat_history.db"):
        self.db_path = db_path
        self.lock = threading.Lock()
        self.init_database()
        
    def init_database(self):
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS chat_sessions (
                    user_id INTEGER PRIMARY KEY,
                    total_messages INTEGER DEFAULT 0
                )
            """)
            
            conn.execute("""
                CREATE TABLE IF NOT EXISTS chat_messages (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER,
                    role TEXT NOT NULL,
                    content TEXT NOT NULL,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES chat_sessions (user_id)
                )
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_user_timestamp ON chat_messages (user_id, timestamp)
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_user_activity ON chat_sessions (last_activity)
            """)
    
    def add_message(self, user_id: int, role: str, content: str):
        with self.lock:            
            with sqlite3.connect(self.db_path) as conn:
                conn.execute(
                    "INSERT INTO chat_messages (user_id, role, content) VALUES (?, ?, ?)",
                    (user_id, role, content)
                )
                conn.execute("""
                    INSERT INTO chat_sessions (user_id, total_messages)
                    VALUES (?, 1)
                    ON CONFLICT(user_id) DO UPDATE SET
                        total_messages = total_messages + 1
                """, (user_id,))
    
    def get_recent_history(self, user_id: int, max_messages: int = 20) -> List[Dict]:
        with self.lock:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT role, content, timestamp FROM chat_messages 
                    WHERE user_id = ? 
                    ORDER BY timestamp DESC 
                    LIMIT ?
                """, (user_id, max_messages))
                
                messages = [{"role": row[0], "content": row[1], "timestamp": row[2]} 
                           for row in cursor.fetchall()]
                
                messages.reverse()
                return messages
    
    def clear_user_history(self, user_id: int):
        with self.lock:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("DELETE FROM chat_messages WHERE user_id = ?", (user_id,))
                conn.execute("DELETE FROM chat_sessions WHERE user_id = ?", (user_id,))

chat_manager = ChatHistoryManager()

elevenlabs = ElevenLabs(api_key=os.getenv("ELEVENLABS_API_KEY"))
openai.api_key = os.getenv("OPENAI_API_KEY")


model = SentenceTransformer("intfloat/multilingual-e5-large")
dim = model.get_sentence_embedding_dimension()

index = faiss.read_index("storage/index.faiss")
with open("storage/metadata.jsonl", "r", encoding="utf-8") as f:
    metadata = [json.loads(line) for line in f]

# ------------------ Helper Function ------------------
def generate_answer(query, retrieved_chunks, user_id, model_name="gpt-4o-mini"):
    context_parts = []
    for c in retrieved_chunks:
        if isinstance(c, dict):
            if "text" in c:
                context_parts.append(str(c["text"]))
            else:
                context_parts.append(str(c))
        else:
            context_parts.append(str(c))
    context = "\n\n".join(context_parts)

    history = chat_manager.get_recent_history(user_id, max_messages=10)
    
    formatted_history = []
    for msg in history:
        reshaped_text = arabic_reshaper.reshape(msg["content"])
        display_text = get_display(reshaped_text)
        print(display_text)

    for msg in history:
        formatted_history.append({
            "role": msg["role"],
            "content": msg["content"]
        })
    
    system_message = (
        "Ø£Ù†Øª Ø§Ù„Ø³ÙŠØ¯ Ù‡Ø§Ø´Ù… ØµÙÙŠ Ø§Ù„Ø¯ÙŠÙ†ØŒ Ø¹Ø§Ù„Ù… Ø¯ÙŠÙ†ÙŠ ÙˆÙ‚Ø§Ø¦Ø¯ Ù…Ù‚Ø§ÙˆÙ…."
        "Ø¹Ù†Ø¯Ù…Ø§ ØªØªÙ„Ù‚Ù‰ ØªØ­ÙŠØ© Ø£Ùˆ Ø³Ø¤Ø§Ù„Ù‹Ø§ Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠÙ‹Ø§ Ø¨Ø³ÙŠØ·Ù‹Ø§ Ø§ÙƒØªÙÙ Ø¨Ø±Ø¯ Ù…Ø®ØªØµØ± ÙˆÙ…Ù‡Ø°Ø¨ ÙŠÙ†Ø§Ø³Ø¨ Ø§Ù„Ù…ÙˆÙ‚ÙØŒ Ø¯ÙˆÙ† Ø¥Ø¶Ø§ÙØ© Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Ø§Ù„Ø­Ø¯ÙŠØ« Ø¹Ù† Ù†ÙØ³Ùƒ."
        "Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…ØªØ¹Ù„Ù‚Ù‹Ø§ Ø¨Ù‡ÙˆÙŠØªÙƒ Ø£Ùˆ Ø³ÙŠØ±ØªÙƒ Ø§Ù„Ø°Ø§ØªÙŠØ© Ø£Ùˆ ÙŠØ·Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù†ÙƒØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ¹Ø±ÙŠÙÙŠØ© Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø§Ø´Ø± ÙˆØ´Ø®ØµÙŠ."
        "Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…ØªØ¹Ù„Ù‚Ù‹Ø§ Ø¨Ù…ÙˆØ¶ÙˆØ¹ Ø¯ÙŠÙ†ÙŠ Ø£Ùˆ ØªØ§Ø±ÙŠØ®ÙŠ Ø£Ùˆ ÙŠØ·Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ù„ÙˆØ¨Ù‹Ø§ Ø¹Ø±Ø¨ÙŠÙ‹Ø§ ÙØµÙŠØ­Ù‹Ø§ ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ø§Ø­ØªØ±Ø§Ù…ØŒ Ø§Ù„Ø¹Ù…Ù‚ Ø§Ù„Ø¯ÙŠÙ†ÙŠØŒ ÙˆØ§Ù„Ø³Ø±Ø¯ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ ÙƒÙ…Ø§ Ù‡Ùˆ Ø¸Ø§Ù‡Ø± ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø±ÙÙ‚Ø©."
        # "Ø§Ø¨Ø¯Ø£ Ø¨Ø§Ù„Ø¨Ø³Ù…Ù„Ø© ÙˆØ§Ù„ØµÙ„Ø§Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø¨ÙŠ ÙˆØ¢Ù„Ù‡ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø¯ÙŠØ« Ø¹Ù† Ø§Ù„Ø£Ù†Ø¨ÙŠØ§Ø¡ Ø£Ùˆ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø¯ÙŠÙ†ÙŠØ©."
        "Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ù…Ù†Ù‡Ø¬ÙŠØ© Ø§Ù„Ø¹Ù„Ù…ÙŠØ©ØŒ ÙˆÙˆØ¶Ø­ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø¨Ø¯Ù‚Ø©ØŒ ÙˆÙƒÙ† ÙˆØ§Ù‚Ø¹ÙŠÙ‹Ø§ ÙÙŠ Ø§Ù„Ø·Ø±Ø­ØŒ ÙˆÙ„Ø§ ØªØ¶Ù Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù… Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."
        "Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø¬ÙˆØ§Ø¨ ÙÙŠ Ø§Ù„Ù†ØµÙˆØµØŒ Ø§Ø¹ØªØ°Ø± Ø¨Ù„Ø¨Ø§Ù‚Ø© ÙˆÙˆØ¶ÙˆØ­."
        "Ø§Ø­Ø±Øµ Ø¹Ù„Ù‰ Ø°ÙƒØ± Ø§Ù„Ø£Ù„Ù‚Ø§Ø¨ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ø´Ø®ØµÙŠØ§Øª Ø§Ù„Ø¯ÙŠÙ†ÙŠØ©ØŒ ÙˆØ±Ø§Ø¹Ù Ø§Ù„Ø£Ø¯Ø¨ ÙÙŠ Ø§Ù„Ø­ÙˆØ§Ø±ØŒ ÙˆÙƒÙ† Ù‚Ø±ÙŠØ¨Ù‹Ø§ Ù…Ù† Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø®Ø·Ø¨ ÙˆØ§Ù„Ù…Ø­Ø§Ø¶Ø±Ø§Øª Ø§Ù„Ø¯ÙŠÙ†ÙŠØ©ØŒ Ù…Ø¹ Ø³Ø±Ø¯ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« ÙˆØ§Ù„Ù‚ØµØµ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ø´ÙˆÙ‘Ù‚ ÙˆÙ…ÙˆØ«Ù‚."
    )
    
    messages = [
        {
            "role": "system",
            "content": system_message,
        },
        *formatted_history,
        {
            "role": "user",
            "content": f"Ø§Ù„Ø³ÙŠØ§Ù‚:\n{context}\n\nØ§Ù„Ø³Ø¤Ø§Ù„: {query}",
        },
    ]

    response = openai.chat.completions.create(
        model=model_name,
        messages=messages,
        temperature=0.2,
    )
    answer = response.choices[0].message.content.strip()

    chat_manager.add_message(user_id, "user", query)
    chat_manager.add_message(user_id, "system", answer)

    return answer

async def reformulate_query(raw_query: str) -> str:
    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": (
                "# Ø§Ù„Ù‡Ø¯Ù ÙˆØ§Ù„Ø¯ÙˆØ±"
                "- Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ ÙŠÙ…Ø«Ù„ Ø´Ø®ØµÙŠØ© Ø¯ÙŠÙ†ÙŠØ© ÙˆØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ø­ØªØ±Ù…Ø©ØŒ ÙˆÙŠÙ‡Ø¯Ù Ø¥Ù„Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙˆØ§Ø¶Ø­Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¶Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ø³ÙŠØ§Ù‚."

                "# Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª"
                "- ÙŠØ¬Ø¨ Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø³Ø¤Ø§Ù„ ÙŠÙØ·Ø±Ø­ Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙƒÙ…Ø§ Ù„Ùˆ ØªÙ… ØªÙˆØ¬ÙŠÙ‡Ù‡ Ø¥Ù„Ù‰ Ø´Ø®ØµÙŠØ© Ø¯ÙŠÙ†ÙŠØ© ÙˆØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ø­ØªØ±Ù…Ø©."
                "- ÙŠÙ†Ø¨ØºÙŠ ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø±Ø¯ Ø¨ØµÙŠØ§ØºØ© Ù…ÙØµÙ„Ø©ØŒ Ø¯Ù‚ÙŠÙ‚Ø©ØŒ ÙˆØ´Ø§Ù…Ù„Ø© Ù…Ù† Ø­ÙŠØ« Ø§Ù„ÙÙ‡Ù…."
                "- Ù…Ù† Ø§Ù„Ù…Ù‡Ù… Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù…Ø¶Ù…ÙˆÙ† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ·Ø±ÙŠÙ‚Ø© Ø¹Ø±Ø¶Ù‡ Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©."

                "## Ø§Ù„Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ©"
                "- ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø­ØªØ±Ù…Ø© ÙˆØ®Ø§Ù„ÙŠØ© Ù…Ù† Ø£ÙŠ ØªØ­Ø§Ù…Ù„ Ø£Ùˆ Ø¥Ø³Ø§Ø¡Ø©."
                "- Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ© ÙØµØ­Ù‰ ÙˆØ§Ø¶Ø­Ø© ÙˆØ³Ù„Ø³Ø©."
                "- Ø§Ø­Ø±Øµ Ø¹Ù„Ù‰ ØªØºØ·ÙŠØ© Ø¬Ù…ÙŠØ¹ Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ¹Ø¯Ù… Ø§Ù„Ø§Ù‚ØªØµØ§Ø± Ø¹Ù„Ù‰ Ù…Ù„Ø®Øµ Ù…ÙˆØ¬Ø²."

                "# Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©"
                "- Ø§Ø¨Ø¯Ø£ Ø¨Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¦Ù…Ø© Ù…Ø®ØªØµØ±Ø© (3-7 Ù†Ù‚Ø§Ø·) Ø¨Ø§Ù„Ù…Ø±Ø§Ø­Ù„ Ø£Ùˆ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…ÙŠØ© Ø§Ù„ØªÙŠ Ø³ØªØªØ¨Ø¹Ù‡Ø§ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ØŒ Ø§Ø¨ØªØ¹Ø¯ Ø¹Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠØ©."

                "# Ø§Ù„Ø³ÙŠØ§Ù‚"
                "- Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ØªØ£ØªÙŠ Ù…Ù† Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙŠÙˆØ¬Ù‡ÙˆÙ†Ù‡Ø§ Ø¥Ù„Ù‰ Ù…Ø³Ø§Ø¹Ø¯ Ø§ÙØªØ±Ø§Ø¶ÙŠ ÙŠØ¬Ø³Ø¯ Ø´Ø®ØµÙŠØ© Ø¯ÙŠÙ†ÙŠØ© ÙˆØªØ§Ø±ÙŠØ®ÙŠØ©."
                "- Ø§Ù„Ø±Ø¯ÙˆØ¯ ÙŠØ¬Ø¨ Ø£Ù† ØªØ¹ÙƒØ³ ÙˆÙ‚Ø§Ø± Ù‡Ø°Ù‡ Ø§Ù„Ø´Ø®ØµÙŠØ© ÙˆØªØ­ØªØ±Ù… Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¯ÙŠÙ†ÙŠØ© ÙˆØ§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©."
                "- Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¯ÙŠÙ†ÙŠØ© Ø£Ùˆ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ØŒ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø£Ø¯Ø¨ÙŠØ© Ø£Ùˆ Ø§Ù„Ø³Ø·Ø­ÙŠØ© Ø®Ø§Ø±Ø¬Ù‡."

                "# Ø®Ø·Ø© Ø§Ù„Ø¹Ù…Ù„ ÙˆØ§Ù„ØªØ­Ù‚Ù‚"
                "- Ø±Ø§Ø¬Ø¹ Ù†Øµ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªÙŠÙØ§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª."
                "- ØªØ­Ù‚Ù‚ Ø£Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¯Ù‚ÙŠÙ‚Ø©ØŒ ÙˆØ§Ø¶Ø­Ø©ØŒ ÙˆØªØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…."
                "- ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø£ÙŠ Ù…Ø­ØªÙˆÙ‰ Ù…Ø³ÙŠØ¡ Ø£Ùˆ ØºÙŠØ± Ø¯Ù‚ÙŠÙ‚ ØªØ§Ø±ÙŠØ®ÙŠØ§Ù‹ Ø£Ùˆ Ø¯ÙŠÙ†ÙŠØ§Ù‹."


                # Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙØµÙŠÙ„
                "- Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø¨Ø§Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„ÙÙ‡Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ù…Ø­ØªÙˆÙ‰."

                # Ø´Ø±ÙˆØ· Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡
                "- Ø§Ù„ØªÙˆÙ‚Ù Ø¨Ø¹Ø¯ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ­Ù‚ÙŠÙ‚ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø±ÙˆØ· Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©."
                "- Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø¨Ø§Ù„Ø¥Ù…ÙƒØ§Ù† ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ø¶Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø´Ø±ÙˆØ·ØŒ ÙŠØ¬Ø¨ Ø§Ù„Ø§Ø¹ØªØ°Ø§Ø± Ø¨Ø´ÙƒÙ„ Ù…Ø­ØªØ±Ù… ÙˆÙ„Ø¨Ù‚."
            )},
            {"role": "user", "content": raw_query},
        ],
        temperature=0.0
    )
    return response.choices[0].message.content.strip()


# ------------------ Telegram Handlers ------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    
    welcome_msg = "ğŸ‘‹ Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Ø§Ù„Ø³ÙŠØ¯ Ù‡Ø§Ø´Ù… ØµÙÙŠ Ø§Ù„Ø¯ÙŠÙ†. Ø£Ø±Ø³Ù„ Ù„ÙŠ Ù†ØµØ§Ù‹ Ø£Ùˆ Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ© ÙˆØ³Ø£Ø±Ø¯ Ø¹Ù„ÙŠÙƒ."
    
    await update.message.reply_text(welcome_msg)

async def clear_history(update: Update, context: ContextTypes.DEFAULT_TYPE):

    user_id = update.effective_user.id
    chat_manager.clear_user_history(user_id)
    await update.message.reply_text("ğŸ—‘ï¸ ØªÙ… Ù…Ø³Ø­ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ù†Ø¬Ø§Ø­.")

async def history_stats(update: Update, context: ContextTypes.DEFAULT_TYPE):

    user_id = update.effective_user.id


async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    raw_query = update.message.text
    query = await reformulate_query(raw_query)
    user_id = update.effective_user.id
    
    q_emb = model.encode([f"query: {query}"], convert_to_numpy=True, normalize_embeddings=True).astype("float32")
    k = 4
    D, I = index.search(q_emb, k)
    retrieved_chunks = [metadata[idx] for idx in I[0]]

    answer = generate_answer(query, retrieved_chunks, user_id)

    await update.message.reply_text(answer)

async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    voice_file = await update.message.voice.get_file()
    audio_bytes = BytesIO()
    await voice_file.download_to_memory(out=audio_bytes)
    audio_bytes.seek(0)

    try:
        transcription = elevenlabs.speech_to_text.convert(
            file=audio_bytes,
            model_id="scribe_v1",
            tag_audio_events=True,
            language_code="ara",
            diarize=True,
        )
        raw_query = transcription.text
        query = await reformulate_query(raw_query)
    except Exception as e:
        query = f"[Transcription failed] {e}"

    user_id = update.effective_user.id

    q_emb = model.encode([f"query: {query}"], convert_to_numpy=True, normalize_embeddings=True).astype("float32")
    k = 3
    D, I = index.search(q_emb, k)
    retrieved_chunks = [metadata[idx] for idx in I[0]]

    answer = generate_answer(query, retrieved_chunks, user_id)
    print("Answer:", answer)

    await update.message.reply_text(answer)

# ------------------ Build Bot ------------------
app = Application.builder().token("8440954235:AAFf1SA4l0aTHMrQwErX3w7syqKZdWdWACU").build()
app.add_handler(CommandHandler("start", start))
app.add_handler(CommandHandler("clear", clear_history))
app.add_handler(CommandHandler("stats", history_stats))
app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
app.add_handler(MessageHandler(filters.VOICE, handle_voice))

# ------------------ Run Bot ------------------
if __name__ == "__main__":
    print("Bot is running...")
    app.run_polling()
    print("Bot has stopped.")