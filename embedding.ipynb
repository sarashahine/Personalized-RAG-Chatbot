{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2ee1c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "model = SentenceTransformer(\"intfloat/multilingual-e5-large\")\n",
    "dim = model.get_sentence_embedding_dimension()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f17ed3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 38 chunks from chunks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "chunks = []\n",
    "\n",
    "folder = \"chunks\"\n",
    "for filename in os.listdir(folder):\n",
    "    if filename.endswith(\".json\"):\n",
    "        path = os.path.join(folder, filename)\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)  # could be a list of chunks\n",
    "            if isinstance(data, list):\n",
    "                chunks.extend(data)  # add all chunks\n",
    "            elif isinstance(data, dict):\n",
    "                chunks.append(data)  # add single chunk\n",
    "\n",
    "print(f\"✅ Loaded {len(chunks)} chunks from {folder}\")\n",
    "\n",
    "texts = [c[\"content\"] for c in chunks]\n",
    "metadata = [\n",
    "    {\n",
    "        \"id\": c[\"chunk_id\"],\n",
    "        \"title\": c[\"title\"],\n",
    "        \"source\": c[\"source\"],\n",
    "        \"text\": c[\"content\"]\n",
    "    }\n",
    "    for c in chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2853af57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding chunks: 100%|██████████| 38/38 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "embeddings = model.encode(\n",
    "    [f\"passage: {t}\" for t in tqdm(texts, desc=\"Encoding chunks\")],\n",
    "    batch_size=16,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ").astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6acaef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stored 38 chunks into FAISS index\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(embeddings)\n",
    "\n",
    "os.makedirs(\"storage\", exist_ok=True)\n",
    "faiss.write_index(index, \"storage/index.faiss\")\n",
    "\n",
    "with open(\"storage/metadata.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for m in metadata:\n",
    "        f.write(json.dumps(m, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"✅ Stored {len(metadata)} chunks into FAISS index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "636f7770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.80997866\n",
      "Chunk: أنا السيد هاشم صفي الدين، وُلدت عام 1964 في دير قانون النهر بجنوب لبنان. نشأت في أسرة ملتزمة، ودرست العلوم الدينية في النجف وقم. أعتز بانتمائي للإسلام والمذهب الشيعي.\n",
      "---\n",
      "Score: 0.80045736\n",
      "Chunk: بسم الله الرحمن الرحيم. والصلاة والسلام على سيدنا أبي القاسم محمد وعلى ال بيته الطيبين الطاهرين. ذكرنا لغاية الان مشهدين من مشاهد خلق ادم وعلم ادم والحجج التي القاها الله عز وجل على الملائكة، وكيف عاند ابليس وخرج عن طاعة الله عز وجل وأبى أن يسجد لادم سلام الله عليه متعللا بأنه من نار، وأن ادم عليه السلام من طين. بعد هذا أصبح ادم موجودا وستبدأ وظائفه وستبدأ المهام تنقى عليه. المهمة الاولى التي ألقيت على ادم هو ان يسكن في الجنة. الجنة التي ستكون سببا لهبوطه الى الارض في نهاية المطاف. الله عز وجل يريد من ادم ان يهبط الى الارض وهذا هو المقصد الاساسي من خلق ادم. من وجود الحياة الدنيا على هذه الارض وتكاثر البشرية. لكن هذا لا يتم تلقائيا. لابد ان يكون للانسان دور فيه لحتى تكون هذه الوظيفة منتزجة بين ما يطلبه الله عز وجل وبين ما يفعله الانسان.\n",
      "---\n",
      "Score: 0.78666365\n",
      "Chunk: ولعل هذا هو المراد من قوله تعالى: يا أيها الناس اتقوا ربكم الذي خلقكم من نفس واحدة وخلق منها زوجها وبث منها رجالا كثيرا ونساء. إذا النفس الواحدة هي المنشأ الواحد، هي المعدن الواحد، وهي الطين المصلصل. في رواية عن الإمام الصادق سلام الله عليه أن الله عز وجل بعد أن أوجد حواء وخلقها وقال لآدم اسكن أنت وزوجك الجنة. طبعا بعد أن خلق حواء أقبلت حواء تتحرك. آدم تعجب قال يا رب ما هذا المخلوق الجميل الحسن؟ فقال له الله عز وجل هذا خلق من خلقي. فيا آدم هذا المخلوق لك. هل تريد أن تتزوجها؟ قال نعم. فقال اخطبها مني. فخطب آدم حواء من الله عز وجل. ثم دب الله تعالى الشهوة في آدم وكان الزواج. ودخلت هي مع آدم إلى جنة الدنيا للعبور إلى عالم الهبوط وعالم الابتلاء.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index(\"storage/index.faiss\")\n",
    "with open(\"storage/metadata.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata = [json.loads(line) for line in f]\n",
    "\n",
    "query = \"شو هي الأسماء اللي علمها الله سبحانه وتعالى للنبي آدم؟\"\n",
    "query = \"مسقط رأس السيد هاشم\"\n",
    "\n",
    "q_emb = model.encode(\n",
    "    [f\"query: {query}\"],\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ").astype(\"float32\")\n",
    "\n",
    "D, I = index.search(q_emb, k=3)  # top-3 results\n",
    "for score, idx in zip(D[0], I[0]):\n",
    "    print(\"Score:\", score)\n",
    "    print(\"Chunk:\", metadata[idx][\"text\"])\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0f302ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def generate_answer(query, retrieved_chunks, model=\"gpt-4o-mini\"):\n",
    "\n",
    "    context = \"\\n\\n\".join([c[\"text\"] for c in retrieved_chunks])\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"أنت مساعد يجيب بناءا على فكر السيد هاشم صفي الدين.\"\n",
    "                \"اعتمد في اجابتك على النصوص المتوفرة في السياق. \"\n",
    "                \"إذا لم يكن الجواب واضحا وكاملا في السياق، قل أنك لا تعرف. \"\n",
    "                \"تكلم باحترام عن الشخصيات الشيعية, مع ذكر الألقاب المناسبة.\"\n",
    "                \"أجب دائمًا باللغة العربية الفصحى الواضحة.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"السياق:\\n{context}\\n\\nالسؤال: {query}\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d82923f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, dict found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m results = [metadata[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m I[\u001b[32m0\u001b[39m]]\n\u001b[32m     12\u001b[39m retrieved_chunks = results\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m answer = \u001b[43mgenerate_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrieved_chunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mgenerate_answer\u001b[39m\u001b[34m(query, retrieved_chunks, model)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_answer\u001b[39m(query, retrieved_chunks, model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     context = \u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mretrieved_chunks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     messages = [\n\u001b[32m     13\u001b[39m         {\n\u001b[32m     14\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m         },\n\u001b[32m     27\u001b[39m     ]\n\u001b[32m     29\u001b[39m     response = openai.chat.completions.create(\n\u001b[32m     30\u001b[39m         model=model,\n\u001b[32m     31\u001b[39m         messages=messages,\n\u001b[32m     32\u001b[39m         temperature=\u001b[32m0.2\u001b[39m,\n\u001b[32m     33\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: sequence item 0: expected str instance, dict found"
     ]
    }
   ],
   "source": [
    "query = \"شو هي الأسماء اللي علمها الله سبحانه وتعالى للنبي آدم؟\"\n",
    "query = \"ما رأي السيد هاشم بالامام علي؟\"\n",
    "\n",
    "q_emb = model.encode([\n",
    "    f\"query: {query}\"\n",
    "], convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
    "\n",
    "k = 3\n",
    "D, I = index.search(q_emb, k)\n",
    "results = [metadata[idx] for idx in I[0]]\n",
    "\n",
    "retrieved_chunks = results\n",
    "answer = generate_answer(query, retrieved_chunks)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
