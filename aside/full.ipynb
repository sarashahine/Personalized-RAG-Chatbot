{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3084f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\OneDrive\\Documents\\GitHub\\Personalized_RAG_Chatbot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 114\u001b[39m\n\u001b[32m    112\u001b[39m base = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mLenovo\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mOneDrive\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mGitHub\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mPersonalized_RAG_Chatbot\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(base, \u001b[33m\"\u001b[39m\u001b[33mcharacter.json\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     character = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m persona_preamble = (\n\u001b[32m    116\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mالشخصية: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcharacter.get(\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mالدور: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcharacter.get(\u001b[33m'\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mالتعليمات: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcharacter.get(\u001b[33m'\u001b[39m\u001b[33mqa_instructions\u001b[39m\u001b[33m'\u001b[39m,{}).get(\u001b[33m'\u001b[39m\u001b[33mpersona_consistency\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    122\u001b[39m )\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# ------------------ Helper Function ------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\json\\decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\json\\decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    353\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from telegram import Update\n",
    "from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes\n",
    "import os\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv\n",
    "from elevenlabs.client import ElevenLabs\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "import faiss\n",
    "import json\n",
    "import sqlite3\n",
    "import threading\n",
    "from typing import Dict, List\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "\n",
    "# ------------------ Load APIs ------------------\n",
    "load_dotenv()\n",
    "\n",
    "class ChatHistoryManager:\n",
    "    def __init__(self, db_path: str = \"chat_history.db\"):\n",
    "        self.db_path = db_path\n",
    "        self.lock = threading.Lock()\n",
    "        self.init_database()\n",
    "        \n",
    "    def init_database(self):\n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            conn.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS chat_sessions (\n",
    "                    user_id INTEGER PRIMARY KEY,\n",
    "                    last_activity TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                    total_messages INTEGER DEFAULT 0,\n",
    "                    session_start TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                )\n",
    "            \"\"\")\n",
    "            \n",
    "            conn.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS chat_messages (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    user_id INTEGER,\n",
    "                    role TEXT NOT NULL,\n",
    "                    content TEXT NOT NULL,\n",
    "                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                    FOREIGN KEY (user_id) REFERENCES chat_sessions (user_id)\n",
    "                )\n",
    "            \"\"\")\n",
    "            \n",
    "            conn.execute(\"\"\"\n",
    "                CREATE INDEX IF NOT EXISTS idx_user_timestamp ON chat_messages (user_id, timestamp)\n",
    "            \"\"\")\n",
    "            \n",
    "            conn.execute(\"\"\"\n",
    "                CREATE INDEX IF NOT EXISTS idx_user_activity ON chat_sessions (last_activity)\n",
    "            \"\"\")\n",
    "    \n",
    "    def add_message(self, user_id: int, role: str, content: str):\n",
    "        with self.lock:            \n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                conn.execute(\n",
    "                    \"INSERT INTO chat_messages (user_id, role, content) VALUES (?, ?, ?)\",\n",
    "                    (user_id, role, content)\n",
    "                )\n",
    "                conn.execute(\"\"\"\n",
    "                    INSERT INTO chat_sessions (user_id, total_messages)\n",
    "                    VALUES (?, 1)\n",
    "                    ON CONFLICT(user_id) DO UPDATE SET\n",
    "                        total_messages = total_messages + 1\n",
    "                \"\"\", (user_id,))\n",
    "    \n",
    "    def get_recent_history(self, user_id: int, max_messages: int = 20) -> List[Dict]:\n",
    "        with self.lock:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                cursor = conn.execute(\"\"\"\n",
    "                    SELECT role, content, timestamp FROM chat_messages \n",
    "                    WHERE user_id = ? \n",
    "                    ORDER BY timestamp DESC \n",
    "                    LIMIT ?\n",
    "                \"\"\", (user_id, max_messages))\n",
    "                \n",
    "                messages = [{\"role\": row[0], \"content\": row[1], \"timestamp\": row[2]} \n",
    "                           for row in cursor.fetchall()]\n",
    "                \n",
    "                messages.reverse()\n",
    "                return messages\n",
    "    \n",
    "    def clear_user_history(self, user_id: int):\n",
    "        with self.lock:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                conn.execute(\"DELETE FROM chat_messages WHERE user_id = ?\", (user_id,))\n",
    "                conn.execute(\"DELETE FROM chat_sessions WHERE user_id = ?\", (user_id,))\n",
    "\n",
    "chat_manager = ChatHistoryManager()\n",
    "\n",
    "elevenlabs = ElevenLabs(api_key=os.getenv(\"ELEVENLABS_API_KEY\"))\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"intfloat/multilingual-e5-large\")\n",
    "dim = model.get_sentence_embedding_dimension()\n",
    "\n",
    "reranker = CrossEncoder(\"Omartificial-Intelligence-Space/ARA-Reranker-V1\")\n",
    "\n",
    "index = faiss.read_index(\"storage/index.faiss\")\n",
    "with open(\"storage/metadata.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata = [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "base = r\"C:\\Users\\Lenovo\\OneDrive\\Documents\\GitHub\\Personalized_RAG_Chatbot\"\n",
    "with open(os.path.join(base, \"character.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    character = json.load(f)\n",
    "persona_preamble = (\n",
    "    f\"الشخصية: {character.get('name','')}\\n\"\n",
    "    f\"الدور: {character.get('role','')}\\n\"\n",
    "    f\"الأسلوب: {', '.join(character.get('speaking_style',{}).get('tone', []))}; \"\n",
    "    f\"اللغة: {character.get('speaking_style',{}).get('language','')}\\n\"\n",
    "    f\"المبادئ: {', '.join(character.get('worldview',{}).get('core_values', []) )}\\n\"\n",
    "    f\"التعليمات: {character.get('qa_instructions',{}).get('persona_consistency','')}\"\n",
    ")\n",
    "# ------------------ Helper Function ------------------\n",
    "def generate_answer(query, retrieved_chunks, user_id, model_name=\"gpt-4o\"):\n",
    "    context_parts = []\n",
    "    for c in retrieved_chunks:\n",
    "        if isinstance(c, dict):\n",
    "            if \"text\" in c:\n",
    "                context_parts.append(str(c[\"text\"]))\n",
    "            else:\n",
    "                context_parts.append(str(c))\n",
    "        else:\n",
    "            context_parts.append(str(c))\n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    history = chat_manager.get_recent_history(user_id, max_messages=10)\n",
    "    \n",
    "    formatted_history = []\n",
    "    for msg in history:\n",
    "        reshaped_text = arabic_reshaper.reshape(msg[\"content\"])\n",
    "        display_text = get_display(reshaped_text)\n",
    "        print(display_text)\n",
    "\n",
    "    for msg in history:\n",
    "        formatted_history.append({\n",
    "            \"role\": msg[\"role\"],\n",
    "            \"content\": msg[\"content\"]\n",
    "        })\n",
    "    \n",
    "    system_message = (\n",
    "        \"أنت السيد هاشم صفي الدين.\"\n",
    "        # \"عندما تتلقى تحية أو سؤالًا اجتماعيًا بسيطًا اكتفِ برد مختصر ومهذب يناسب الموقف، دون إضافة أي معلومات من قاعدة البيانات أو الحديث عن نفسك.\"\n",
    "        # \"إذا كان السؤال متعلقًا بهويتك أو سيرتك الذاتية أو يطلب معلومات عنك، استخدم المعلومات التعريفية المتوفرة في السياق للإجابة بشكل مباشر وشخصي.\"\n",
    "        \"استخدم أسلوبًا عربيًا فصيحًا يجمع بين الاحترام، العمق الديني، والسرد التاريخي كما هو ظاهر في النصوص المرفقة.\"\n",
    "        \"إذا لم تجد الجواب في النصوص، اعتذر بلباقة ووضوح ولا تعطي اي معلومة من خارج السياق.\"\n",
    "        \"احرص على ذكر الألقاب المناسبة للشخصيات الدينية، وراعِ الأدب في الحوار.\"\n",
    "        \"\"\n",
    "    )\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"system\", \"content\": f\"معلومات عن السيد هاشم صفي الدين:\\n{persona_preamble}\"},\n",
    "        {\"role\": \"system\", \"content\": f\"الرسائل السابقة:\\n{formatted_history}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"السياق:\\n{context}\\n\\nالسؤال: {query}\"},\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "\n",
    "    chat_manager.add_message(user_id, \"user\", query)\n",
    "    chat_manager.add_message(user_id, \"system\", answer)\n",
    "\n",
    "    return answer\n",
    "\n",
    "async def reformulate_query(raw_query: str) -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": (\n",
    "\n",
    "            )},\n",
    "            {\"role\": \"user\", \"content\": raw_query},\n",
    "        ],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# ------------------ Telegram Handlers ------------------\n",
    "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    user_id = update.effective_user.id\n",
    "    \n",
    "    welcome_msg = \"👋 مرحباً! أنا السيد هاشم صفي الدين. أرسل لي نصاً أو رسالة صوتية وسأرد عليك.\"\n",
    "    \n",
    "    await update.message.reply_text(welcome_msg)\n",
    "\n",
    "async def clear_history(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "\n",
    "    user_id = update.effective_user.id\n",
    "    chat_manager.clear_user_history(user_id)\n",
    "    await update.message.reply_text(\"🗑️ تم مسح تاريخ المحادثة بنجاح.\")\n",
    "\n",
    "async def history_stats(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "\n",
    "    user_id = update.effective_user.id\n",
    "\n",
    "\n",
    "async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    raw_query = update.message.text\n",
    "    query = await reformulate_query(raw_query)\n",
    "    query = raw_query\n",
    "    user_id = update.effective_user.id\n",
    "    \n",
    "    q_emb = model.encode([f\"query: {query}\"], convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
    "    k = 4\n",
    "    D, I = index.search(q_emb, k)\n",
    "    retrieved_chunks = [metadata[idx] for idx in I[0]]\n",
    "\n",
    "    answer = generate_answer(query, retrieved_chunks, user_id)\n",
    "\n",
    "    await update.message.reply_text(answer)\n",
    "\n",
    "async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    voice_file = await update.message.voice.get_file()\n",
    "    audio_bytes = BytesIO()\n",
    "    await voice_file.download_to_memory(out=audio_bytes)\n",
    "    audio_bytes.seek(0)\n",
    "\n",
    "    try:\n",
    "        transcription = elevenlabs.speech_to_text.convert(\n",
    "            file=audio_bytes,\n",
    "            model_id=\"scribe_v1\",\n",
    "            tag_audio_events=True,\n",
    "            language_code=\"ara\",\n",
    "            diarize=True,\n",
    "        )\n",
    "        raw_query = transcription.text\n",
    "        query = await reformulate_query(raw_query)\n",
    "        query = raw_query\n",
    "    except Exception as e:\n",
    "        query = f\"[Transcription failed] {e}\"\n",
    "\n",
    "    user_id = update.effective_user.id\n",
    "\n",
    "    q_emb = model.encode([f\"query: {query}\"], convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
    "    k = 4\n",
    "    D, I = index.search(q_emb, k)\n",
    "    retrieved_chunks = [metadata[idx] for idx in I[0]]\n",
    "\n",
    "    answer = generate_answer(query, retrieved_chunks, user_id)\n",
    "    print(\"Answer:\", answer)\n",
    "\n",
    "    await update.message.reply_text(answer)\n",
    "\n",
    "# ------------------ Build Bot ------------------\n",
    "app = Application.builder().token(\"8440954235:AAFf1SA4l0aTHMrQwErX3w7syqKZdWdWACU\").build()\n",
    "app.add_handler(CommandHandler(\"start\", start))\n",
    "app.add_handler(CommandHandler(\"clear\", clear_history))\n",
    "app.add_handler(CommandHandler(\"stats\", history_stats))\n",
    "app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))\n",
    "app.add_handler(MessageHandler(filters.VOICE, handle_voice))\n",
    "\n",
    "await app.initialize()\n",
    "await app.start()\n",
    "await app.updater.start_polling()\n",
    "\n",
    "# ------------------ Run Bot ------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Bot is running...\")\n",
    "    app.run_polling()\n",
    "    print(\"Bot has stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8c7999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\Users\\Lenovo\\OneDrive\\Documents\\GitHub\\Personalized_RAG_Chatbot\n",
      "Exists: True Size: 631\n",
      "Preview: '{\\n  \"name\": \"السيد هاشم صفي الدين\",\\n  \"role\": \"قائد ديني وسياسي مرتبط بخط المقاومة\",\\n  \"speaking_style\": {\\n    \"language\": \"العربية الفصحى\",\\n    \"tone\": [\\n      \"وقور\",\\n      \"دعوي-إرشادي\",\\n      \"تحفيزي\",\\n      \"واقعي-تحليلي\"\\n    ]\\n  },\\n  \"worldview\": {\\n    \"core_values\": [\\n      \"التوحيد\",\\n      \"المقاومة\",\\n      \"العفة\",\\n      \"قصر الأمل\"\\n    ]\\n  },\\n  \"qa_instructions\": {\\n    \"persona_consisten'\n",
      "JSON OK: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import os, json, pathlib\n",
    "\n",
    "p = pathlib.Path(\"character.json\")\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"Exists:\", p.exists(), \"Size:\", p.stat().st_size if p.exists() else \"N/A\")\n",
    "\n",
    "# Preview first 400 chars to spot issues\n",
    "if p.exists():\n",
    "    raw = p.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "    print(\"Preview:\", repr(raw[:400]))\n",
    "\n",
    "# Validate JSON and pinpoint error\n",
    "try:\n",
    "    character = json.loads(raw)\n",
    "    print(\"JSON OK:\", type(character))\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON error at line {e.lineno}, col {e.colno}: {e.msg}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
