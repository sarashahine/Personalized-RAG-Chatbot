{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 86 chunks from /Users/mohamad/Documents/GitHub/Personalized-RAG-Chatbot/chunks.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "chunks = []\n",
    "\n",
    "folder = r\"/Users/mohamad/Documents/GitHub/Personalized-RAG-Chatbot/chunks.json\"\n",
    "\n",
    "with open(folder, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    if isinstance(data, list):\n",
    "        chunks.extend(data)\n",
    "    elif isinstance(data, dict):\n",
    "        chunks.append(data)\n",
    "    else:\n",
    "        print(f\"Skipping {folder} as it is not a list or dictionary.\")\n",
    "\n",
    "print(f\"âœ… Loaded {len(chunks)} chunks from {folder}\")\n",
    "\n",
    "texts = [c[\"content\"] for c in chunks]\n",
    "metadata = [\n",
    "    {\n",
    "        \"id\": c[\"id\"],\n",
    "        \"title\": c[\"title\"],\n",
    "        \"source\": c[\"source\"],\n",
    "        \"text\": c[\"content\"]\n",
    "    }\n",
    "    for c in chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding texts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:37<00:00,  2.32it/s]\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "texts = [c[\"content\"] for c in chunks]\n",
    "embeddings = []\n",
    "\n",
    "for text in tqdm(texts, desc=\"Embedding texts\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    emb = np.array(response.data[0].embedding, dtype=\"float32\")\n",
    "    emb /= np.linalg.norm(emb)\n",
    "    embeddings.append(emb)\n",
    "\n",
    "embeddings = np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FAISS index created and saved with 86 vectors.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import os\n",
    "\n",
    "dim = embeddings.shape[1]\n",
    "\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(embeddings)\n",
    "\n",
    "os.makedirs(\"storage\", exist_ok=True)\n",
    "faiss.write_index(index, \"storage/openai_index.faiss\")\n",
    "\n",
    "print(f\"âœ… FAISS index created and saved with {index.ntotal} vectors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model=\"text-embedding-3-small\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "    embedding = response.data[0].embedding\n",
    "    return np.array(embedding, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "os.makedirs(\"storage\", exist_ok=True)\n",
    "\n",
    "metadata = [\n",
    "    {\n",
    "        \"id\": i,\n",
    "        \"title\": c.get(\"title\", \"\"),\n",
    "        \"source\": c.get(\"source\", \"\"),\n",
    "        \"content\": c[\"content\"]\n",
    "    }\n",
    "    for i, c in enumerate(chunks)\n",
    "]\n",
    "\n",
    "\n",
    "with open(\"storage/chunks_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top relevant chunks:\n",
      "\n",
      "Result 1 (score: 0.4982):\n",
      "Ø«Ù… Ù„Ø§ ÙŠØªØºÙŠØ± ÙˆÙ„Ø§ ÙŠØªØ¨Ø¯Ù„ ÙˆÙ„Ø§ ÙŠØªØ£Ø«Ø± ÙˆÙ„Ø§ ÙŠÙ†ÙØ¹Ù„. Ù…Ø§ Ù‡Ø°Ø§ Ù‚Ù„Ø¨ Ù…Ø­Ø¬ÙˆØ¨ ÙˆÙ‡Ø°Ø§ Ù‚Ù„Ø¨ Ù„Ø§ ÙŠØ´Ø¹Ø± Ù‡Ø°Ù‡ Ù„Ø§ ÙŠØ´Ø¹Ø± Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø¹Ø§Ø¡ ÙˆØ£Ù‡Ù…ÙŠØªÙ‡ Ø¨Ù„ Ù„Ø§ ÙŠØ³ØªØ·Ø¹Ù† Ø·Ø¹Ù…Ù‡ ÙˆÙ„Ø°ØªÙ‡. Ù„Ø§Ù† Ù„Ø°Ø© Ø§Ù„Ø¯Ø¹Ø§Ø¡ ØªÙ‚Ø±Ø¨Ùƒ Ù…Ù† Ø§Ù„Ù„Ù‡ Ø³Ø¨Ø­Ø§Ù†Ù‡ ÙˆØªØ¹Ø§Ù„Ù‰. ÙˆÙ„Ø°Ø§ ÙˆØ±Ø¯ Ø¹Ù†Ø¯Ù†Ø§ Ø§Ù† ÙÙŠ Ø¨Ø¹Ø¶ Ø¨Ø¹Ø¶ Ù…Ù† ÙŠØ¯Ø¹Ùˆ. Ø¨Ø¹Ø¶ Ø§Ù„Ø±ÙˆØ§ÙŠØ§Øª ÙˆØ±Ø¯ Ø¹Ù†Ø¯Ù†Ø§ Ø£Ù† Ù…Ù† ÙŠØ¯Ø¹Ùˆ Ø§Ù„Ù„Ù‡ Ø¹Ø² ÙˆØ¬Ù„ Ù‡Ùˆ ÙŠØ¹Ø±Ù ÙÙŠ Ù‚Ø±Ø§Ø±Ø© Ù†ÙØ³Ù‡ ÙˆÙÙŠ Ø®Ø§ØªÙ…Ø© Ø¯Ø¹Ø§Ø¦Ù‡ Ø£Ù† Ø¯Ø¹Ø§Ø¤Ù‡ ÙˆØµÙ„ Ø£Ùˆ Ù„Ù… ÙŠØµÙ„. ÙƒÙŠÙØŸ Ø¥Ø°Ø§ Ø´Ø¹Ø± ÙÙŠ Ù‚Ù„Ø¨Ù‡ Ø§Ù†ÙØ¹Ø§Ù„Ø§. ÙˆÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø±ÙˆØ§ÙŠØ§Øª ØªØªØ­Ø¯Ø« Ø¹Ù† Ù‚Ø·Ø±Ø© Ø¯Ù…Ø¹ ØªÙ†Ø²Ù„ Ù…Ù† Ø¹ÙŠÙ†ÙŠÙ‡. Ù‡Ø°Ù‡ Ø¥Ø´Ø§Ø±Ø© Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø¯Ø¹Ø§Ø¡ ÙˆØ¹Ù„Ù‰ ÙˆØµÙˆÙ„ Ø§Ù„Ø¯Ø¹Ø§Ø¡ Ù„Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø§Ù†ÙØ¹Ø§Ù„Ø§ ÙˆÙ„Ø£Ù† Ù‡Ù†Ø§Ùƒ ØªØ£Ø«Ø±Ø§ Ø¹Ù„Ù‰ Ø£ÙŠ Ø­Ø§Ù„.\n",
      "{'id': 56, 'title': 'Ø¹Ø§Ø´ÙˆØ±Ø§Ø¡ 2016 - 1438 Ù‡Ø¬Ø±ÙŠ Â» ÙƒÙ„Ù…Ø© Ø§Ù„Ø³ÙŠØ¯ Ù‡Ø§Ø´Ù… ØµÙÙŠ Ø§Ù„Ø¯ÙŠÙ† ÙÙŠ Ø§Ù„Ù„ÙŠÙ„Ø© Ø§Ù„Ø³Ø§Ø¯Ø³Ø© Ù…Ù† Ø´Ù‡Ø± Ù…Ø­Ø±Ù… Ø§Ù„Ø­Ø±Ø§Ù….', 'source': 'Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø³ÙŠØ¯ Ù‡Ø§Ø´Ù… ØµÙÙŠ Ø§Ù„Ø¯ÙŠÙ†'}\n",
      "\n",
      "Result 2 (score: 0.4262):\n",
      "Ø­ÙŠØ§ØªÙ†Ø§ Ù‡ÙˆÙ‰. Ø­ÙŠØ§ØªÙ†Ø§ Ø´Ù‡ÙˆØ©. Ø­ÙŠØ§ØªÙ†Ø§ Ù†Ø²ÙˆØ© Ø­ÙŠØ§ØªÙ†Ø§. Ø±ØºØ¨Ø© Ø­ÙŠÙ†Ø¦Ø° Ù†Ø­Ù† Ù…Ø­Ø¬ÙˆØ¨ÙˆÙ† Ø¹Ù† Ø§Ù„Ù„Ù‡ Ø¹Ø² ÙˆØ¬Ù„. Ø­ÙŠÙ†Ù…Ø§ ÙŠØºÙ„Ø¨Ù†Ø§ Ø§Ù„Ù‡ÙˆÙ‰. Ø§Ù„Ø¯Ø¹Ø§Ø¡ Ù„Ø§ ÙŠÙ†ÙØ¹. Ø§Ù„ØªÙˆØ³Ù„ Ù„Ø§ ÙŠÙ†ÙØ¹. Ø§Ù„Ø±Ø¬ÙˆØ¹ Ø¥Ù„Ù‰ Ø§Ù„Ù„Ù‡ Ø¨Ø¹Ø¯ Ø¥Ø°Ù† Ù„Ø§ ÙŠÙ†ÙØ¹. Ù„Ø§ Ø¨Ø¯ Ø£Ù† ØªÙ‚Ù„Ø¹ Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ù‡ÙˆÙ‰ Ø­ØªÙ‰ ÙŠØ³ØªÙ‚ÙŠÙ… Ø§Ù„Ø£Ù…Ø±. ÙˆÙÙŠ Ø§Ù„Ø­Ø¯ÙŠØ« Ø§Ù„Ù‚Ø¯Ø³ÙŠ Ø¥Ù† Ø£Ø¯Ù†ÙŠ ÙŠÙ‚ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØªØ¹Ø§Ù„Ù‰ Ø¥Ù† Ø£Ø¯Ù†ÙŠ Ù…Ø§ Ø£ØµÙ†Ø¹ Ø¨Ø§Ù„Ø¹Ø¨Ø¯ Ø¥Ø°Ø§ Ø¢Ø«Ø± Ø´Ù‡ÙˆØªÙ‡ Ø¹Ù„Ù‰ Ø·Ø§Ø¹ØªÙŠ Ø£Ù† Ø£Ø­Ø±Ù…Ù‡ Ù„Ø°ÙŠØ° Ù…Ù†Ø§Ø¬Ø§Ø©.Ø´ÙˆÙÙˆØ§ Ø§Ù„Ù„ÙŠ Ø¨ÙŠÙ‚Ø¹Ø¯ Ø¨Ø§Ù„Ø¯Ø¹Ø§Ø¡ Ø¨Ù†Ø­ÙŠ Ù„ÙŠÙ„Ø© Ø§Ù„Ù‚Ø¯Ø± Ù…Ø¹ Ø³ÙŠØ¯ Ø§Ù„Ø´Ù‡Ø¯Ø§Ø¡ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ù…Ø¨Ø§Ø±Ùƒ ÙˆÙÙŠ ÙƒÙ„ Ø§Ù„Ù…Ø³Ø§Ø¬Ø¯ ÙˆÙƒÙ„ Ø§Ù„Ù…Ø³Ø§Ø¬Ø¯ Ù…Ø¨Ø§Ø±ÙƒØ©. Ø§Ù†Ø³Ø§Ù† ÙŠØ­ÙŠ Ù„ÙŠÙ„Ø© Ø§Ù„Ù‚Ø¯Ø± Ø¨Ø§Ø¯Ø¹ÙŠØ© Ø·ÙˆÙŠÙ„Ø© ÙˆØ±Ø¯Øª Ø¹Ù† Ø§Ù‡Ù„ Ø§Ù„Ø¨ÙŠØª Ø¹Ù„ÙŠÙ‡Ù… Ø§Ù„Ø³Ù„Ø§Ù….\n",
      "{'id': 55, 'title': 'Ø¹Ø§Ø´ÙˆØ±Ø§Ø¡ 2016 - 1438 Ù‡Ø¬Ø±ÙŠ Â» ÙƒÙ„Ù…Ø© Ø§Ù„Ø³ÙŠØ¯ Ù‡Ø§Ø´Ù… ØµÙÙŠ Ø§Ù„Ø¯ÙŠÙ† ÙÙŠ Ø§Ù„Ù„ÙŠÙ„Ø© Ø§Ù„Ø³Ø§Ø¯Ø³Ø© Ù…Ù† Ø´Ù‡Ø± Ù…Ø­Ø±Ù… Ø§Ù„Ø­Ø±Ø§Ù….', 'source': 'Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø³ÙŠØ¯ Ù‡Ø§Ø´Ù… ØµÙÙŠ Ø§Ù„Ø¯ÙŠÙ†'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "\n",
    "index = faiss.read_index(\"storage/openai_index.faiss\")\n",
    "\n",
    "with open(\"storage/chunks_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "def search_index(query, k=5, min_score=0.4):\n",
    "    query_vector = get_embedding(query).reshape(1, -1)\n",
    "    query_vector /= np.linalg.norm(query_vector)\n",
    "\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "\n",
    "    results = []\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        if dist >= min_score:\n",
    "            chunk_data = metadata[idx]\n",
    "            results.append({\n",
    "                \"score\": float(dist),\n",
    "                \"chunk\": chunk_data[\"content\"],\n",
    "                \"metadata\": {\n",
    "                    \"id\": chunk_data[\"id\"],\n",
    "                    \"title\": chunk_data[\"title\"],\n",
    "                    \"source\": chunk_data[\"source\"]\n",
    "                }\n",
    "        })\n",
    "    return results\n",
    "\n",
    "query = \"Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªØ¯Ù„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¯Ø¹Ø§Ø¡ Ø§Ù„Ø¥Ù†Ø³Ø§Ù†ØŸ\"\n",
    "query = \"ÙƒÙŠÙ ÙŠÙ…ÙƒÙ† Ù„Ù„Ø¥Ù†Ø³Ø§Ù† Ø£Ù† ÙŠØ¹Ø±Ù Ø£Ù† Ø¯Ø¹Ø§Ø¡Ù‡ Ù‚Ø¯ Ø§Ø³ØªØ¬ÙŠØ¨ØŸ\"\n",
    "results = search_index(query, k=6)\n",
    "\n",
    "print(\"Top relevant chunks:\")\n",
    "for i, res in enumerate(results, 1):\n",
    "    print(f\"\\nResult {i} (score: {res['score']:.4f}):\")\n",
    "    print(res[\"chunk\"])\n",
    "    print(res[\"metadata\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformulate_query(query, history=None, model=\"gpt-4o-mini\"):\n",
    "\n",
    "    system_prompt = (\n",
    "        \"Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ù‡Ù†ÙŠØ© Ø¶Ù…Ù† Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª (RAG system).\"\n",
    "        \"Ø§Ø¨Ø¯Ø£ Ø¨Ø®Ø·Ø© Ù…Ø®ØªØµØ±Ø© (Checklist) Ù…Ù† 3-5 Ø®Ø·ÙˆØ§Øª Ù…ÙØ§Ù‡ÙŠÙ…ÙŠØ© Ù„ÙƒÙ„ Ù…Ø±Ø­Ù„Ø© ØªØ¹Ø§Ù„Ø¬ ÙÙŠÙ‡Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„.\"\n",
    "        \"Ø£Ø¹Ø¯ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ù†ÙØ³ Ø§Ù„ØµÙŠØºØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…ØªÙƒÙ„Ù… (Ù„Ø§ ØªØºÙŠÙ‘Ø± Ø§Ù„Ø¶Ù…Ø§Ø¦Ø± Ø£Ùˆ ÙˆØ¬Ù‡Ø© Ø§Ù„Ù†Ø¸Ø±).\"\n",
    "        \"Ù„Ø§ ØªØ¶Ù Ø£Ùˆ ØªØ­Ø°Ù Ø£ÙŠ Ù…Ø¹Ù†Ù‰ Ø¬Ø¯ÙŠØ¯.\"\n",
    "        \"Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ§Ø¶Ø­Ù‹Ø§ ÙˆÙ…Ø¨Ø§Ø´Ø±Ù‹Ø§ØŒ Ø£Ø¹ÙØ¯ Ø¹Ø±Ø¶Ù‡ ÙƒÙ…Ø§ Ù‡Ùˆ Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ø·ÙÙŠÙ Ù„Ù„Ø£Ø³Ù„ÙˆØ¨ ÙÙ‚Ø·.\"\n",
    "        \"Ø§Ù„Ù‡Ø¯Ù Ù‡Ùˆ Ø¬Ø¹Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø£ÙˆØ¶Ø­ ÙˆØ£ÙƒØ«Ø± Ø±Ø³Ù…ÙŠØ© Ø¯ÙˆÙ† ØªØºÙŠÙŠØ± Ù…Ø¹Ù†Ø§Ù‡ Ø£Ùˆ ØµÙŠØºØ© Ø§Ù„Ù…ØªÙƒÙ„Ù….\"\n",
    "        \"Ø¨Ø¹Ø¯ ØªØ¹Ø¯ÙŠÙ„ ÙƒÙ„ Ø³Ø¤Ø§Ù„ØŒ Ø£ØªØ­Ù‚Ù‚ ÙÙŠ Ø¬Ù…Ù„Ø© Ø£Ùˆ Ø¬Ù…Ù„ØªÙŠÙ† Ù…Ù† Ø£Ù† Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø­Ù‚Ù‚ Ø§Ù„ÙˆØ¶ÙˆØ­ ÙˆØ§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø¯ÙˆÙ† ØªØºÙŠÙŠØ± Ø§Ù„Ø¬ÙˆÙ‡Ø±ØŒ Ø«Ù… Ø§Ù†ØªÙ‚Ù„ Ù„Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ.\"\n",
    "        \"Ø§ÙƒØªØ¨ ÙÙ‚Ø· Ø§Ù„ØµÙŠØºØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„Ø³Ø¤Ø§Ù„ Ù…Ù† Ø¯ÙˆÙ† Ø§Ù„Ø´Ø±Ø­.\"\n",
    "    )\n",
    "    if history:\n",
    "        user_prompt = f\"Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚:\\n{history}\\n\\nØ§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ:\\n{query}\"\n",
    "    else:\n",
    "        user_prompt = f\"Ø£Ø¹Ø¯ ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ:\\n\\n{query}\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def generate_answer(query, retrieved_chunks, model=\"gpt-4o-mini\"):\n",
    "\n",
    "    context = \"\\n\\n\".join([c[\"chunk\"] for c in retrieved_chunks])\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ÙŠØ¬ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù†Ù‡ Ø§Ù„Ø³ÙŠØ¯ Ù‡Ø§Ø´Ù… ØµÙÙŠ Ø§Ù„Ø¯ÙŠÙ†.\"\n",
    "                \"Ø§Ø¹ØªÙ…Ø¯ ÙÙŠ Ø§Ø¬Ø§Ø¨ØªÙƒ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ ÙÙ‚Ø·.\"\n",
    "                \"Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ø¬ÙˆØ§Ø¨ ÙˆØ§Ø¶Ø­Ø§ ÙˆÙƒØ§Ù…Ù„Ø§ ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ØŒ Ù‚Ù„ Ø£Ù†Ùƒ Ù„Ø§ ØªØ¹Ø±Ù. \"\n",
    "                \"ØªÙƒÙ„Ù… Ø¨Ø§Ø­ØªØ±Ø§Ù… Ø¹Ù† Ø§Ù„Ø´Ø®ØµÙŠØ§Øª Ø§Ù„Ø´ÙŠØ¹ÙŠØ©, Ù…Ø¹ Ø°ÙƒØ± Ø§Ù„Ø£Ù„Ù‚Ø§Ø¨ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©.\"\n",
    "                \"Ø£Ø¬Ø¨ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„ÙˆØ§Ø¶Ø­Ø©.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Ø§Ù„Ø³ÙŠØ§Ù‚:\\n{context}\\n\\nØ§Ù„Ø³Ø¤Ø§Ù„: {query}\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÙŠÙ…ÙƒÙ† Ù„Ù„Ø¥Ù†Ø³Ø§Ù† Ø£Ù† ÙŠØ¹Ø±Ù Ø£Ù† Ø¯Ø¹Ø§Ø¡Ù‡ Ù‚Ø¯ Ø§Ø³ØªØ¬ÙŠØ¨ Ù…Ù† Ø®Ù„Ø§Ù„ Ø´Ø¹ÙˆØ±Ù‡ ÙÙŠ Ù‚Ù„Ø¨Ù‡ Ø¨Ø§Ù†ÙØ¹Ø§Ù„ Ø£Ùˆ ØªØ£Ø«Ø± Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¯Ø¹Ø§Ø¡. ÙƒÙ…Ø§ ÙˆØ±Ø¯ ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø±ÙˆØ§ÙŠØ§Øª Ø£Ù† Ù†Ø²ÙˆÙ„ Ù‚Ø·Ø±Ø© Ø¯Ù…Ø¹ Ù…Ù† Ø§Ù„Ø¹ÙŠÙ† ÙŠÙØ¹ØªØ¨Ø± Ø¥Ø´Ø§Ø±Ø© Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø¯Ø¹Ø§Ø¡ ÙˆÙˆØµÙˆÙ„Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ù„Ù‡ Ø³Ø¨Ø­Ø§Ù†Ù‡ ÙˆØªØ¹Ø§Ù„Ù‰. Ø¥Ø°Ø§ Ø´Ø¹Ø± Ø§Ù„Ø´Ø®Øµ Ø¨Ù„Ø°Ø© Ø§Ù„Ø¯Ø¹Ø§Ø¡ ÙˆÙ‚Ø±Ø¨Ù‡ Ù…Ù† Ø§Ù„Ù„Ù‡ØŒ ÙÙ‡Ø°Ø§ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø£Ù† Ø¯Ø¹Ø§Ø¡Ù‡ Ù‚Ø¯ ÙˆØµÙ„.\n"
     ]
    }
   ],
   "source": [
    "query = \"Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªØ¯Ù„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¯Ø¹Ø§Ø¡ Ø§Ù„Ø¥Ù†Ø³Ø§Ù†ØŸ\"\n",
    "query = \"ÙƒÙŠÙ ÙŠÙ…ÙƒÙ† Ù„Ù„Ø¥Ù†Ø³Ø§Ù† Ø£Ù† ÙŠØ¹Ø±Ù Ø£Ù† Ø¯Ø¹Ø§Ø¡Ù‡ Ù‚Ø¯ Ø§Ø³ØªØ¬ÙŠØ¨ØŸ\"\n",
    "\n",
    "results = search_index(query, k=3)\n",
    "\n",
    "retrieved_chunks = results\n",
    "answer = generate_answer(query, retrieved_chunks)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Reformulated: ÙƒÙŠÙ ÙŠÙ…ÙƒÙ† Ù„Ù„Ø¥Ù†Ø³Ø§Ù† Ø£Ù† ÙŠØ¹Ø±Ù Ø£Ù† Ø¯Ø¹Ø§Ø¡Ù‡ Ù‚Ø¯ Ø§Ø³ØªØ¬ÙŠØ¨ØŸ\n"
     ]
    }
   ],
   "source": [
    "query = \"ÙƒÙŠÙ ÙŠØ¹Ø±Ù Ø§Ù„Ø§Ù†Ø³Ø§Ù† Ø§Ù† Ø¯Ø¹Ø§Ø¦Ù‡ Ù…Ø³ØªØ¬Ø§Ø¨ØŸ\"\n",
    "# query =  \"Ø³Ù„Ø§Ù…\"\n",
    "\n",
    "refined_query = reformulate_query(query, history=None)\n",
    "print(\"ğŸ”„ Reformulated:\", refined_query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
